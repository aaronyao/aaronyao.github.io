<!DOCTYPE html>
<html>
<head>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta charset="utf-8" />
</head>

<body style="margin: 0;">

<div id="p32" style="overflow: hidden; position: relative; background-color: white; width: 909px; height: 1286px;">

<!-- Begin shared CSS values -->
<style class="shared-css" type="text/css" >
.t {
	transform-origin: bottom left;
	z-index: 2;
	position: absolute;
	white-space: pre;
	overflow: visible;
	line-height: 1.5;
}
.text-container {
	white-space: pre;
}
@supports (-webkit-touch-callout: none) {
	.text-container {
		white-space: normal;
	}
}
</style>
<!-- End shared CSS values -->


<!-- Begin inline CSS -->
<style type="text/css" >

#t1_32{left:307px;bottom:1186px;letter-spacing:0.01px;word-spacing:0.57px;}
#t2_32{left:95px;bottom:1132px;letter-spacing:-0.24px;word-spacing:1.41px;}
#t3_32{left:112px;bottom:1111px;letter-spacing:-0.22px;word-spacing:1.07px;}
#t4_32{left:455px;bottom:1111px;letter-spacing:-0.21px;}
#t5_32{left:507px;bottom:1111px;letter-spacing:-0.15px;word-spacing:0.47px;}
#t6_32{left:95px;bottom:1077px;letter-spacing:-0.24px;word-spacing:3.04px;}
#t7_32{left:112px;bottom:1056px;letter-spacing:-0.22px;word-spacing:0.73px;}
#t8_32{left:112px;bottom:1035px;letter-spacing:-0.19px;word-spacing:0.76px;}
#t9_32{left:112px;bottom:1015px;letter-spacing:-0.22px;word-spacing:0.6px;}
#ta_32{left:471px;bottom:1015px;letter-spacing:-0.15px;word-spacing:0.47px;}
#tb_32{left:95px;bottom:980px;letter-spacing:-0.21px;word-spacing:1.56px;}
#tc_32{left:112px;bottom:960px;letter-spacing:-0.17px;word-spacing:0.29px;}
#td_32{left:112px;bottom:939px;letter-spacing:-0.21px;word-spacing:0.57px;}
#te_32{left:329px;bottom:939px;letter-spacing:-0.16px;word-spacing:0.48px;}
#tf_32{left:563px;bottom:939px;letter-spacing:-0.15px;word-spacing:0.47px;}
#tg_32{left:95px;bottom:904px;letter-spacing:-0.22px;word-spacing:0.6px;}
#th_32{left:112px;bottom:884px;letter-spacing:-0.24px;word-spacing:0.9px;}
#ti_32{left:112px;bottom:863px;letter-spacing:-0.21px;word-spacing:0.57px;}
#tj_32{left:289px;bottom:863px;letter-spacing:-0.16px;word-spacing:0.48px;}
#tk_32{left:523px;bottom:863px;letter-spacing:-0.15px;word-spacing:0.47px;}
#tl_32{left:95px;bottom:829px;letter-spacing:-0.31px;word-spacing:0.74px;}
#tm_32{left:112px;bottom:808px;letter-spacing:-0.25px;word-spacing:2.78px;}
#tn_32{left:336px;bottom:808px;letter-spacing:-0.24px;word-spacing:2.57px;}
#to_32{left:542px;bottom:808px;letter-spacing:-0.15px;}
#tp_32{left:581px;bottom:808px;letter-spacing:-0.18px;word-spacing:2.67px;}
#tq_32{left:783px;bottom:808px;letter-spacing:-0.21px;}
#tr_32{left:112px;bottom:786px;letter-spacing:0.18px;}
#ts_32{left:410px;bottom:787px;}
#tt_32{left:95px;bottom:753px;letter-spacing:-0.22px;word-spacing:0.66px;}
#tu_32{left:112px;bottom:732px;letter-spacing:-0.21px;word-spacing:0.76px;}
#tv_32{left:777px;bottom:732px;letter-spacing:-0.17px;}
#tw_32{left:112px;bottom:711px;letter-spacing:-0.16px;word-spacing:0.48px;}
#tx_32{left:304px;bottom:711px;letter-spacing:-0.15px;word-spacing:0.47px;}
#ty_32{left:95px;bottom:677px;letter-spacing:-0.21px;word-spacing:1.78px;}
#tz_32{left:111px;bottom:656px;letter-spacing:-0.2px;word-spacing:1.71px;}
#t10_32{left:508px;bottom:656px;letter-spacing:-0.18px;word-spacing:1.17px;}
#t11_32{left:110px;bottom:636px;letter-spacing:-0.29px;}
#t12_32{left:170px;bottom:636px;letter-spacing:-0.18px;word-spacing:1.03px;}
#t13_32{left:95px;bottom:601px;letter-spacing:-0.25px;word-spacing:2.01px;}
#t14_32{left:434px;bottom:601px;letter-spacing:-0.22px;word-spacing:1.87px;}
#t15_32{left:112px;bottom:581px;letter-spacing:-0.18px;}
#t16_32{left:201px;bottom:581px;letter-spacing:-0.16px;word-spacing:0.48px;}
#t17_32{left:435px;bottom:581px;letter-spacing:-0.15px;word-spacing:0.47px;}
#t18_32{left:95px;bottom:546px;letter-spacing:-0.24px;word-spacing:1.47px;}
#t19_32{left:111px;bottom:525px;letter-spacing:-0.2px;word-spacing:2.17px;}
#t1a_32{left:112px;bottom:505px;letter-spacing:-0.16px;word-spacing:0.92px;}
#t1b_32{left:713px;bottom:505px;letter-spacing:-0.15px;word-spacing:0.88px;}
#t1c_32{left:112px;bottom:484px;letter-spacing:-0.17px;}
#t1d_32{left:242px;bottom:484px;letter-spacing:-0.15px;word-spacing:0.47px;}
#t1e_32{left:95px;bottom:450px;letter-spacing:-0.34px;word-spacing:1.19px;}
#t1f_32{left:112px;bottom:429px;letter-spacing:-0.15px;word-spacing:0.74px;}
#t1g_32{left:706px;bottom:429px;letter-spacing:-0.25px;}
#t1h_32{left:740px;bottom:429px;letter-spacing:-0.15px;word-spacing:0.47px;}
#t1i_32{left:95px;bottom:395px;letter-spacing:-0.23px;word-spacing:1.51px;}
#t1j_32{left:112px;bottom:374px;letter-spacing:-0.21px;word-spacing:0.59px;}
#t1k_32{left:533px;bottom:374px;letter-spacing:-0.16px;word-spacing:0.5px;}
#t1l_32{left:766px;bottom:374px;letter-spacing:-0.15px;word-spacing:0.48px;}
#t1m_32{left:95px;bottom:339px;letter-spacing:-0.26px;word-spacing:0.62px;}
#t1n_32{left:112px;bottom:319px;letter-spacing:-0.18px;word-spacing:0.72px;}
#t1o_32{left:755px;bottom:319px;letter-spacing:-0.1px;}
#t1p_32{left:812px;bottom:319px;}
#t1q_32{left:111px;bottom:298px;letter-spacing:-0.18px;word-spacing:2.3px;}
#t1r_32{left:195px;bottom:297px;letter-spacing:0.18px;}
#t1s_32{left:503px;bottom:298px;}
#t1t_32{left:95px;bottom:264px;letter-spacing:-0.26px;word-spacing:0.71px;}
#t1u_32{left:111px;bottom:243px;letter-spacing:-0.21px;word-spacing:0.58px;}
#t1v_32{left:112px;bottom:222px;letter-spacing:-0.18px;word-spacing:-0.01px;}
#t1w_32{left:112px;bottom:202px;letter-spacing:-0.18px;word-spacing:0.87px;}
#t1x_32{left:112px;bottom:181px;letter-spacing:-0.17px;word-spacing:0.51px;}
#t1y_32{left:245px;bottom:181px;letter-spacing:-0.15px;}
#t1z_32{left:283px;bottom:181px;letter-spacing:-0.18px;word-spacing:1.14px;}
#t20_32{left:504px;bottom:180px;letter-spacing:0.18px;}
#t21_32{left:812px;bottom:181px;}
#t22_32{left:95px;bottom:146px;letter-spacing:-0.3px;word-spacing:5.4px;}
#t23_32{left:112px;bottom:126px;letter-spacing:-0.23px;word-spacing:1.52px;}
#t24_32{left:801px;bottom:68px;letter-spacing:0.1px;}

.s0_32{font-size:12px;font-family:XCharter-Roman_vh;color:#000;}
.s1_32{font-size:17px;font-family:XCharter-Roman_vh;color:#000;}
.s2_32{font-size:17px;font-family:XCharter-Italic_6r;color:#000;}
.s3_32{font-size:18px;font-family:LMMono10-Regular_6t;color:#00F;}
.t.v0_32{transform:scaleX(1.02);}
.t.v1_32{transform:scaleX(0.988);}
.t.v2_32{transform:scaleX(0.979);}
.t.v3_32{transform:scaleX(1.006);}
.t.v4_32{transform:scaleX(0.987);}
.t.v5_32{transform:scaleX(0.992);}
.t.v6_32{transform:scaleX(0.994);}
</style>
<!-- End inline CSS -->

<!-- Begin embedded font definitions -->
<style id="fonts32" type="text/css" >

@font-face {
	font-family: LMMono10-Regular_6t;
	src: url("fonts/LMMono10-Regular_6t.woff") format("woff");
}

@font-face {
	font-family: XCharter-Italic_6r;
	src: url("fonts/XCharter-Italic_6r.woff") format("woff");
}

@font-face {
	font-family: XCharter-Roman_vh;
	src: url("fonts/XCharter-Roman_vh.woff") format("woff");
}

</style>
<!-- End embedded font definitions -->

<!-- Begin page background -->
<div id="pg32Overlay" style="width:100%; height:100%; position:absolute; z-index:1; background-color:rgba(0,0,0,0); -webkit-user-select: none;"></div>
<div id="pg32" style="-webkit-user-select: none;"><object width="909" height="1286" data="32/32.svg" type="image/svg+xml" id="pdf32" style="width:909px; height:1286px; -moz-transform:scale(1); z-index: 0;"></object></div>
<!-- End page background -->


<!-- Begin text definitions (Positioned/styled in CSS) -->
<div class="text-container"><span id="t1_32" class="t s0_32">Gemini: A Family of Highly Capable Multimodal Models </span>
<span id="t2_32" class="t v0_32 s1_32">Ashish V. Thapliyal, Jordi Pont-Tuset, Xi Chen, and Radu Soricut. Crossmodal-3600: A massively </span>
<span id="t3_32" class="t s1_32">multilingual multimodal evaluation dataset. In </span><span id="t4_32" class="t s2_32">EMNLP</span><span id="t5_32" class="t s1_32">, 2022. </span>
<span id="t6_32" class="t v0_32 s1_32">Kocmi Tom, Eleftherios Avramidis, Rachel Bawden, Ondřej Bojar, Anton Dvorkovich, Christian </span>
<span id="t7_32" class="t s1_32">Federmann, Mark Fishel, Markus Freitag, Thamme Gowda, Roman Grundkiewicz, et al. Findings </span>
<span id="t8_32" class="t v1_32 s1_32">of the 2023 conference on machine translation (wmt23): Llms are here but not quite there yet. In </span>
<span id="t9_32" class="t s2_32">WMT23-Eighth Conference on Machine Translation</span><span id="ta_32" class="t s1_32">, pages 198–216, 2023. </span>
<span id="tb_32" class="t v0_32 s1_32">Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée </span>
<span id="tc_32" class="t v2_32 s1_32" data-mappings='[[90,"ffi"]]'>Lacroix, BaptisteRozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and eﬃcient </span>
<span id="td_32" class="t s1_32">foundation language models. </span><span id="te_32" class="t s2_32">arXiv preprint arXiv:2302.13971</span><span id="tf_32" class="t s1_32">, 2023a. </span>
<span id="tg_32" class="t v3_32 s1_32">Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay </span>
<span id="th_32" class="t v4_32 s1_32">Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and </span>
<span id="ti_32" class="t s1_32" data-mappings='[[0,"fi"]]'>ﬁne-tuned chat models. </span><span id="tj_32" class="t s2_32">arXiv preprint arXiv:2307.09288</span><span id="tk_32" class="t s1_32">, 2023b. </span>
<span id="tl_32" class="t s1_32">Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz </span>
<span id="tm_32" class="t v0_32 s1_32">Kaiser, and Illia Polosukhin. </span><span id="tn_32" class="t v0_32 s1_32">Attention is all you need. </span><span id="to_32" class="t v0_32 s2_32">CoRR</span><span id="tp_32" class="t v0_32 s1_32">, abs/1706.03762, 2017. </span><span id="tq_32" class="t v0_32 s1_32">URL </span>
<span id="tr_32" class="t s3_32">http://arxiv.org/abs/1706.03762</span><span id="ts_32" class="t s1_32">. </span>
<span id="tt_32" class="t v4_32 s1_32">Petar Veličković, Adrià Puigdomènech Badia, David Budden, Razvan Pascanu, Andrea Banino, Misha </span>
<span id="tu_32" class="t s1_32">Dashevskiy, Raia Hadsell, and Charles Blundell. The clrs algorithmic reasoning benchmark. </span><span id="tv_32" class="t s2_32">arXiv </span>
<span id="tw_32" class="t s2_32">preprint arXiv:2205.15659</span><span id="tx_32" class="t s1_32">, 2022. </span>
<span id="ty_32" class="t v0_32 s1_32">Manoj Vishwanathan, Ronak Shah, Kyung Ki Kim, and Minsu Choi. Silent data corruption (sdc) </span>
<span id="tz_32" class="t v0_32 s1_32">vulnerability of gpu on various gpgpu workloads. In </span><span id="t10_32" class="t v0_32 s2_32">2015 International SoC Design Conference </span>
<span id="t11_32" class="t s2_32">(ISOCC)</span><span id="t12_32" class="t s1_32">, pages 11–12, 2015. doi: 10.1109/ISOCC.2015.7401681. </span>
<span id="t13_32" class="t v0_32 s1_32">Changhan Wang, Anne Wu, and Juan Pino. </span><span id="t14_32" class="t v0_32 s1_32">Covost 2 and massively multilingual speech-to-text </span>
<span id="t15_32" class="t s1_32">translation. </span><span id="t16_32" class="t s2_32">arXiv preprint arXiv:2007.10310</span><span id="t17_32" class="t s1_32">, 2020. </span>
<span id="t18_32" class="t v0_32 s1_32">Changhan Wang, Morgane Riviere, Ann Lee, Anne Wu, Chaitanya Talnikar, Daniel Haziza, Mary </span>
<span id="t19_32" class="t v0_32 s1_32">Williamson, Juan Pino, and Emmanuel Dupoux. Voxpopuli: A large-scale multilingual speech </span>
<span id="t1a_32" class="t v0_32 s1_32">corpus for representation learning, semi-supervised learning and interpretation. </span><span id="t1b_32" class="t v0_32 s2_32">arXiv preprint </span>
<span id="t1c_32" class="t s2_32">arXiv:2101.00390</span><span id="t1d_32" class="t s1_32">, 2021. </span>
<span id="t1e_32" class="t v0_32 s1_32">Xin Wang, Jiawei Wu, Junkun Chen, Lei Li, Yuan-Fang Wang, and William Yang Wang. VATEX: A </span>
<span id="t1f_32" class="t s1_32">large-scale, high-quality multilingual dataset for video-and-language research. In </span><span id="t1g_32" class="t s2_32">ICCV</span><span id="t1h_32" class="t s1_32">, 2019. </span>
<span id="t1i_32" class="t v0_32 s1_32">Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Self-consistency </span>
<span id="t1j_32" class="t s1_32">improves chain of thought reasoning in language models. </span><span id="t1k_32" class="t s2_32">arXiv preprint arXiv:2203.11171</span><span id="t1l_32" class="t s1_32">, 2022. </span>
<span id="t1m_32" class="t v3_32 s1_32">Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, </span>
<span id="t1n_32" class="t v2_32 s1_32">and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. </span><span id="t1o_32" class="t v2_32 s2_32">NeurIPS</span><span id="t1p_32" class="t v2_32 s1_32">, </span>
<span id="t1q_32" class="t s1_32">2022. URL </span><span id="t1r_32" class="t s3_32">https://arxiv.org/abs/2201.11903</span><span id="t1s_32" class="t s1_32">. </span>
<span id="t1t_32" class="t v5_32 s1_32" data-mappings='[[54,"ffi"]]'>Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griﬃn, Jonathan Uesato, Po-Sen Huang, Myra </span>
<span id="t1u_32" class="t v6_32 s1_32">Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, Zac Kenton, Sasha Brown, Will Hawkins, Tom </span>
<span id="t1v_32" class="t v2_32 s1_32">Stepleton, Courtney Biles, Abeba Birhane, Julia Haas, Laura Rimell, Lisa Anne Hendricks, William S. </span>
<span id="t1w_32" class="t v0_32 s1_32" data-mappings='[[26,"ff"]]'>Isaac, Sean Legassick, Geoﬀrey Irving, and Iason Gabriel. Ethical and social risks of harm from </span>
<span id="t1x_32" class="t v6_32 s1_32">language models. </span><span id="t1y_32" class="t v6_32 s2_32">CoRR</span><span id="t1z_32" class="t v6_32 s1_32">, abs/2112.04359, 2021. URL </span><span id="t20_32" class="t s3_32">https://arxiv.org/abs/2112.04359</span><span id="t21_32" class="t v6_32 s1_32">. </span>
<span id="t22_32" class="t v0_32 s1_32">David Wetherall, Abdul Kabbani, Van Jacobson, Jim Winget, Yuchung Cheng, Brad Morrey, </span>
<span id="t23_32" class="t v0_32 s1_32">Uma Parthavi Moravapalle, Phillipa Gill, Steven Knight, and Amin Vahdat. Improving network </span>
<span id="t24_32" class="t s0_32">32 </span></div>
<!-- End text definitions -->


</div>
</body>
</html>
