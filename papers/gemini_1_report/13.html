<!DOCTYPE html>
<html>
<head>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta charset="utf-8" />
</head>

<body style="margin: 0;">

<div id="p13" style="overflow: hidden; position: relative; background-color: white; width: 909px; height: 1286px;">

<!-- Begin shared CSS values -->
<style class="shared-css" type="text/css" >
.t {
	transform-origin: bottom left;
	z-index: 2;
	position: absolute;
	white-space: pre;
	overflow: visible;
	line-height: 1.5;
}
.text-container {
	white-space: pre;
}
@supports (-webkit-touch-callout: none) {
	.text-container {
		white-space: normal;
	}
}
</style>
<!-- End shared CSS values -->


<!-- Begin inline CSS -->
<style type="text/css" >

#t1_13{left:307px;bottom:1186px;letter-spacing:0.01px;word-spacing:0.57px;}
#t2_13{left:121px;bottom:1132px;letter-spacing:-0.18px;word-spacing:0.49px;}
#t3_13{left:95px;bottom:1111px;letter-spacing:-0.4px;word-spacing:1.77px;}
#t4_13{left:210px;bottom:1111px;}
#t5_13{left:220px;bottom:1111px;letter-spacing:-0.22px;word-spacing:1.63px;}
#t6_13{left:95px;bottom:1090px;letter-spacing:-0.19px;word-spacing:-0.27px;}
#t7_13{left:95px;bottom:1070px;letter-spacing:-0.2px;word-spacing:0.76px;}
#t8_13{left:95px;bottom:1049px;letter-spacing:-0.21px;word-spacing:1.25px;}
#t9_13{left:95px;bottom:1028px;letter-spacing:-0.17px;word-spacing:0.5px;}
#ta_13{left:95px;bottom:1008px;letter-spacing:-0.19px;word-spacing:0.6px;}
#tb_13{left:95px;bottom:987px;letter-spacing:-0.18px;word-spacing:0.5px;}
#tc_13{left:457px;bottom:995px;}
#td_13{left:469px;bottom:987px;letter-spacing:-0.25px;word-spacing:0.65px;}
#te_13{left:121px;bottom:956px;letter-spacing:-0.22px;word-spacing:0.08px;}
#tf_13{left:186px;bottom:956px;letter-spacing:-0.37px;word-spacing:0.57px;}
#tg_13{left:251px;bottom:956px;}
#th_13{left:260px;bottom:956px;letter-spacing:-0.19px;}
#ti_13{left:296px;bottom:956px;letter-spacing:-0.2px;word-spacing:0.22px;}
#tj_13{left:95px;bottom:935px;letter-spacing:-0.17px;word-spacing:0.48px;}
#tk_13{left:95px;bottom:914px;letter-spacing:-0.2px;word-spacing:0.73px;}
#tl_13{left:95px;bottom:894px;letter-spacing:-0.18px;word-spacing:0.61px;}
#tm_13{left:95px;bottom:873px;letter-spacing:-0.24px;word-spacing:0.68px;}
#tn_13{left:397px;bottom:873px;}
#to_13{left:407px;bottom:873px;letter-spacing:-0.23px;word-spacing:0.63px;}
#tp_13{left:203px;bottom:837px;letter-spacing:0.05px;word-spacing:0.44px;}
#tq_13{left:391px;bottom:837px;letter-spacing:0.07px;word-spacing:0.36px;}
#tr_13{left:620px;bottom:837px;letter-spacing:-0.05px;word-spacing:0.6px;}
#ts_13{left:391px;bottom:824px;letter-spacing:0.08px;}
#tt_13{left:496px;bottom:824px;letter-spacing:0.04px;}
#tu_13{left:620px;bottom:824px;letter-spacing:0.04px;}
#tv_13{left:203px;bottom:800px;letter-spacing:0.07px;word-spacing:0.35px;}
#tw_13{left:391px;bottom:800px;letter-spacing:0.09px;}
#tx_13{left:496px;bottom:800px;letter-spacing:0.09px;}
#ty_13{left:620px;bottom:800px;letter-spacing:0.09px;}
#tz_13{left:203px;bottom:785px;letter-spacing:0.05px;}
#t10_13{left:391px;bottom:785px;letter-spacing:0.09px;}
#t11_13{left:496px;bottom:785px;letter-spacing:0.09px;}
#t12_13{left:620px;bottom:785px;letter-spacing:0.09px;}
#t13_13{left:203px;bottom:771px;letter-spacing:0.04px;}
#t14_13{left:391px;bottom:771px;letter-spacing:0.09px;}
#t15_13{left:496px;bottom:771px;letter-spacing:0.09px;}
#t16_13{left:620px;bottom:771px;letter-spacing:0.09px;}
#t17_13{left:203px;bottom:756px;letter-spacing:0.03px;word-spacing:0.45px;}
#t18_13{left:391px;bottom:756px;letter-spacing:0.09px;}
#t19_13{left:496px;bottom:756px;letter-spacing:0.09px;}
#t1a_13{left:620px;bottom:756px;letter-spacing:0.09px;}
#t1b_13{left:203px;bottom:742px;letter-spacing:0.06px;word-spacing:0.39px;}
#t1c_13{left:391px;bottom:742px;letter-spacing:0.09px;}
#t1d_13{left:496px;bottom:742px;letter-spacing:0.09px;}
#t1e_13{left:620px;bottom:742px;letter-spacing:0.09px;}
#t1f_13{left:203px;bottom:727px;letter-spacing:0.02px;word-spacing:0.48px;}
#t1g_13{left:391px;bottom:727px;letter-spacing:0.09px;}
#t1h_13{left:496px;bottom:727px;letter-spacing:0.09px;}
#t1i_13{left:620px;bottom:727px;letter-spacing:0.09px;}
#t1j_13{left:203px;bottom:705px;letter-spacing:-0.01px;}
#t1k_13{left:391px;bottom:705px;letter-spacing:0.09px;}
#t1l_13{left:496px;bottom:705px;letter-spacing:0.09px;}
#t1m_13{left:620px;bottom:705px;letter-spacing:0.09px;}
#t1n_13{left:95px;bottom:664px;letter-spacing:-0.7px;word-spacing:1.65px;}
#t1o_13{left:153px;bottom:664px;}
#t1p_13{left:162px;bottom:664px;letter-spacing:-0.21px;word-spacing:0.85px;}
#t1q_13{left:491px;bottom:664px;letter-spacing:-0.2px;word-spacing:0.62px;}
#t1r_13{left:585px;bottom:664px;letter-spacing:-0.37px;word-spacing:1.03px;}
#t1s_13{left:654px;bottom:664px;}
#t1t_13{left:663px;bottom:664px;letter-spacing:-0.19px;}
#t1u_13{left:701px;bottom:664px;letter-spacing:-0.15px;word-spacing:0.61px;}
#t1v_13{left:95px;bottom:644px;letter-spacing:-0.2px;word-spacing:0.58px;}
#t1w_13{left:121px;bottom:602px;letter-spacing:-0.21px;word-spacing:-0.24px;}
#t1x_13{left:95px;bottom:581px;letter-spacing:-0.21px;word-spacing:0.5px;}
#t1y_13{left:95px;bottom:561px;letter-spacing:-0.22px;word-spacing:0.67px;}
#t1z_13{left:95px;bottom:540px;letter-spacing:-0.19px;word-spacing:0.5px;}
#t20_13{left:95px;bottom:519px;letter-spacing:-0.17px;word-spacing:0.76px;}
#t21_13{left:759px;bottom:519px;letter-spacing:-0.17px;}
#t22_13{left:95px;bottom:499px;letter-spacing:-0.22px;word-spacing:0.65px;}
#t23_13{left:131px;bottom:499px;}
#t24_13{left:141px;bottom:499px;letter-spacing:-0.19px;}
#t25_13{left:178px;bottom:499px;letter-spacing:-0.26px;word-spacing:0.76px;}
#t26_13{left:615px;bottom:499px;}
#t27_13{left:624px;bottom:499px;letter-spacing:-0.22px;word-spacing:0.59px;}
#t28_13{left:95px;bottom:478px;letter-spacing:-0.23px;word-spacing:0.62px;}
#t29_13{left:189px;bottom:442px;letter-spacing:0.03px;word-spacing:0.47px;}
#t2a_13{left:359px;bottom:442px;letter-spacing:0.08px;word-spacing:0.34px;}
#t2b_13{left:358px;bottom:428px;letter-spacing:0.06px;}
#t2c_13{left:486px;bottom:442px;letter-spacing:0.09px;word-spacing:0.34px;}
#t2d_13{left:485px;bottom:428px;letter-spacing:0.06px;}
#t2e_13{left:612px;bottom:442px;letter-spacing:-0.02px;word-spacing:0.55px;}
#t2f_13{left:611px;bottom:428px;letter-spacing:0.06px;}
#t2g_13{left:189px;bottom:405px;letter-spacing:0.06px;}
#t2h_13{left:359px;bottom:405px;letter-spacing:0.09px;}
#t2i_13{left:486px;bottom:405px;letter-spacing:0.09px;}
#t2j_13{left:612px;bottom:405px;letter-spacing:0.09px;}
#t2k_13{left:189px;bottom:390px;letter-spacing:0.06px;}
#t2l_13{left:359px;bottom:390px;letter-spacing:0.09px;}
#t2m_13{left:486px;bottom:390px;letter-spacing:0.09px;}
#t2n_13{left:612px;bottom:390px;letter-spacing:0.09px;}
#t2o_13{left:189px;bottom:376px;letter-spacing:0.09px;}
#t2p_13{left:359px;bottom:376px;letter-spacing:0.09px;}
#t2q_13{left:486px;bottom:376px;letter-spacing:0.09px;}
#t2r_13{left:612px;bottom:376px;letter-spacing:0.09px;}
#t2s_13{left:189px;bottom:361px;letter-spacing:0.08px;word-spacing:0.37px;}
#t2t_13{left:359px;bottom:361px;letter-spacing:0.09px;}
#t2u_13{left:486px;bottom:361px;letter-spacing:0.09px;}
#t2v_13{left:612px;bottom:361px;letter-spacing:0.09px;}
#t2w_13{left:189px;bottom:347px;letter-spacing:0.02px;}
#t2x_13{left:359px;bottom:347px;letter-spacing:0.09px;}
#t2y_13{left:486px;bottom:347px;letter-spacing:0.09px;}
#t2z_13{left:612px;bottom:347px;letter-spacing:0.09px;}
#t30_13{left:189px;bottom:332px;letter-spacing:0.09px;}
#t31_13{left:359px;bottom:332px;letter-spacing:0.09px;}
#t32_13{left:486px;bottom:332px;letter-spacing:0.09px;}
#t33_13{left:612px;bottom:332px;letter-spacing:0.09px;}
#t34_13{left:189px;bottom:318px;letter-spacing:0.06px;}
#t35_13{left:359px;bottom:318px;letter-spacing:0.09px;}
#t36_13{left:486px;bottom:318px;letter-spacing:0.09px;}
#t37_13{left:612px;bottom:318px;letter-spacing:0.09px;}
#t38_13{left:189px;bottom:295px;letter-spacing:-0.17px;word-spacing:0.84px;}
#t39_13{left:359px;bottom:295px;letter-spacing:0.09px;}
#t3a_13{left:486px;bottom:295px;letter-spacing:0.09px;}
#t3b_13{left:612px;bottom:295px;letter-spacing:0.09px;}
#t3c_13{left:95px;bottom:255px;letter-spacing:-0.72px;word-spacing:0.66px;}
#t3d_13{left:149px;bottom:255px;}
#t3e_13{left:156px;bottom:255px;letter-spacing:-0.16px;word-spacing:-0.37px;}
#t3f_13{left:417px;bottom:255px;letter-spacing:-0.21px;word-spacing:-0.41px;}
#t3g_13{left:95px;bottom:234px;letter-spacing:-0.16px;word-spacing:-0.56px;}
#t3h_13{left:748px;bottom:234px;letter-spacing:-0.23px;}
#t3i_13{left:95px;bottom:213px;letter-spacing:-0.22px;word-spacing:0.67px;}
#t3j_13{left:131px;bottom:213px;}
#t3k_13{left:140px;bottom:213px;letter-spacing:-0.19px;}
#t3l_13{left:177px;bottom:213px;letter-spacing:-0.12px;}
#t3m_13{left:113px;bottom:163px;}
#t3n_13{left:120px;bottom:157px;letter-spacing:-0.19px;word-spacing:0.46px;}
#t3o_13{left:95px;bottom:140px;letter-spacing:-0.14px;word-spacing:1.89px;}
#t3p_13{left:700px;bottom:140px;letter-spacing:-0.14px;word-spacing:1.65px;}
#t3q_13{left:95px;bottom:124px;letter-spacing:-0.18px;word-spacing:0.48px;}
#t3r_13{left:194px;bottom:124px;}
#t3s_13{left:801px;bottom:68px;letter-spacing:0.1px;}

.s0_13{font-size:12px;font-family:XCharter-Roman_vh;color:#000;}
.s1_13{font-size:17px;font-family:XCharter-Roman_vh;color:#000;}
.s2_13{font-size:17px;font-family:XCharter-Roman_vh;color:#00F;}
.s3_13{font-size:12px;font-family:XCharter-Roman_vh;color:#00F;}
.s4_13{font-size:9px;font-family:XCharter-Roman_vh;color:#000;}
.s5_13{font-size:12px;font-family:XCharter-Bold_vg;color:#00F;}
.s6_13{font-size:17px;font-family:txsys_6y;color:#000;}
.s7_13{font-size:17px;font-family:XCharter-Bold_vg;color:#000;}
.s8_13{font-size:11px;font-family:XCharter-Roman_vh;color:#000;}
.s9_13{font-size:14px;font-family:XCharter-Roman_vh;color:#000;}
.sa_13{font-size:14px;font-family:XCharter-Roman_vh;color:#00F;}
.t.v0_13{transform:scaleX(1.02);}
.t.v1_13{transform:scaleX(0.979);}
.t.v2_13{transform:scaleX(0.98);}
.t.v3_13{transform:scaleX(1.008);}
.t.v4_13{transform:scaleX(1.007);}
.t.v5_13{transform:scaleX(0.987);}
.t.v6_13{transform:scaleX(1.006);}
</style>
<!-- End inline CSS -->

<!-- Begin embedded font definitions -->
<style id="fonts13" type="text/css" >

@font-face {
	font-family: XCharter-Bold_vg;
	src: url("fonts/XCharter-Bold_vg.woff") format("woff");
}

@font-face {
	font-family: XCharter-Roman_vh;
	src: url("fonts/XCharter-Roman_vh.woff") format("woff");
}

@font-face {
	font-family: txsys_6y;
	src: url("fonts/txsys_6y.woff") format("woff");
}

</style>
<!-- End embedded font definitions -->

<!-- Begin page background -->
<div id="pg13Overlay" style="width:100%; height:100%; position:absolute; z-index:1; background-color:rgba(0,0,0,0); -webkit-user-select: none;"></div>
<div id="pg13" style="-webkit-user-select: none;"><object width="909" height="1286" data="13/13.svg" type="image/svg+xml" id="pdf13" style="width:909px; height:1286px; -moz-transform:scale(1); z-index: 0;"></object></div>
<!-- End page background -->


<!-- Begin text definitions (Positioned/styled in CSS) -->
<div class="text-container"><span id="t1_13" class="t s0_13">Gemini: A Family of Highly Capable Multimodal Models </span>
<span id="t2_13" class="t s1_13" data-mappings='[[3,"fi"]]'>We ﬁnd that Gemini Ultra is state of the art across a wide range of image-understanding bench- </span>
<span id="t3_13" class="t v0_13 s1_13">marks in Table </span><span id="t4_13" class="t v0_13 s2_13">7</span><span id="t5_13" class="t v0_13 s1_13">. It achieves strong performance across a diverse set of tasks such as answering </span>
<span id="t6_13" class="t v1_13 s1_13">questions on natural images and scanned documents as well as understanding infographics, charts and </span>
<span id="t7_13" class="t v2_13 s1_13">science diagrams. When compared against publicly reported results from other models (most notably </span>
<span id="t8_13" class="t v0_13 s1_13" data-mappings='[[60,"fi"]]'>GPT-4V), Gemini is better in zero-shot evaluation by a signiﬁcant margin. It also exceeds several </span>
<span id="t9_13" class="t v3_13 s1_13" data-mappings='[[30,"fi"],[37,"fi"]]'>existing models that are speciﬁcally ﬁne-tuned on the benchmark’s training sets for the majority of </span>
<span id="ta_13" class="t s1_13" data-mappings='[[58,"fi"]]'>tasks. The capabilities of the Gemini models lead to signiﬁcant improvements in the state of the art </span>
<span id="tb_13" class="t s1_13">on academic benchmarks like MathVista (+3.1%) </span>
<span id="tc_13" class="t s3_13">6 </span>
<span id="td_13" class="t s1_13">or InfographicVQA (+5.2%). </span>
<span id="te_13" class="t v1_13 s1_13">MMMU (</span><span id="tf_13" class="t v1_13 s2_13">Yue et al.</span><span id="tg_13" class="t v1_13 s1_13">, </span><span id="th_13" class="t v1_13 s2_13">2023</span><span id="ti_13" class="t v1_13 s1_13">) is a recently released evaluation benchmark, which consists of questions </span>
<span id="tj_13" class="t v4_13 s1_13">about images across 6 disciplines with multiple subjects within each discipline that require college- </span>
<span id="tk_13" class="t v0_13 s1_13">level knowledge to solve these questions. Gemini Ultra achieves the best score on this benchmark </span>
<span id="tl_13" class="t v5_13 s1_13">advancing the state-of-the-art result by more than 5 percentage points and outperforms the previous </span>
<span id="tm_13" class="t s1_13">best result in 5 of 6 disciplines (see Table </span><span id="tn_13" class="t s2_13">8</span><span id="to_13" class="t s1_13">), thus showcasing its multimodal reasoning capabilities. </span>
<span id="tp_13" class="t s0_13">MMMU (val) </span><span id="tq_13" class="t s0_13">Gemini Ultra (0-shot) </span><span id="tr_13" class="t s0_13">GPT-4V (0-shot) </span>
<span id="ts_13" class="t s4_13">Maj@32 </span><span id="tt_13" class="t s4_13">pass@1 </span><span id="tu_13" class="t s4_13">pass@1 </span>
<span id="tv_13" class="t s0_13">Art &amp; Design </span><span id="tw_13" class="t s5_13">74.2 </span><span id="tx_13" class="t s0_13">70.0 </span><span id="ty_13" class="t s0_13">65.8 </span>
<span id="tz_13" class="t s0_13">Business </span><span id="t10_13" class="t s5_13">62.7 </span><span id="t11_13" class="t s0_13">56.7 </span><span id="t12_13" class="t s0_13">59.3 </span>
<span id="t13_13" class="t s0_13">Science </span><span id="t14_13" class="t s0_13">49.3 </span><span id="t15_13" class="t s0_13">48.0 </span><span id="t16_13" class="t s5_13">54.7 </span>
<span id="t17_13" class="t s0_13">Health &amp; Medicine </span><span id="t18_13" class="t s5_13">71.3 </span><span id="t19_13" class="t s0_13">67.3 </span><span id="t1a_13" class="t s0_13">64.7 </span>
<span id="t1b_13" class="t s0_13">Humanities &amp; Social Science </span><span id="t1c_13" class="t s5_13">78.3 </span><span id="t1d_13" class="t s0_13">78.3 </span><span id="t1e_13" class="t s0_13">72.5 </span>
<span id="t1f_13" class="t s0_13">Technology &amp; Engineering </span><span id="t1g_13" class="t s5_13">53.0 </span><span id="t1h_13" class="t s0_13">47.1 </span><span id="t1i_13" class="t s0_13">36.7 </span>
<span id="t1j_13" class="t s0_13">Overall </span><span id="t1k_13" class="t s5_13">62.4 </span><span id="t1l_13" class="t s0_13">59.4 </span><span id="t1m_13" class="t s0_13">56.8 </span>
<span id="t1n_13" class="t v0_13 s1_13">Table 8 </span><span id="t1o_13" class="t s6_13">| </span><span id="t1p_13" class="t v0_13 s7_13">Gemini Ultra performance on the MMMU </span><span id="t1q_13" class="t v0_13 s1_13">benchmark (</span><span id="t1r_13" class="t v0_13 s2_13">Yue et al.</span><span id="t1s_13" class="t v0_13 s1_13">, </span><span id="t1t_13" class="t v0_13 s2_13">2023</span><span id="t1u_13" class="t v0_13 s1_13">) per discipline. </span>
<span id="t1v_13" class="t s1_13">Each discipline covers multiple subjects, requiring college-level knowledge and complex reasoning. </span>
<span id="t1w_13" class="t v1_13 s1_13">Gemini models are also capable of operating across modalities and a diverse set of global languages </span>
<span id="t1x_13" class="t v1_13 s1_13">simultaneously, both for image understanding tasks (e.g., images containing text in Icelandic) and for </span>
<span id="t1y_13" class="t v1_13 s1_13">generation tasks (e.g., generating image descriptions for a wide range of languages). We evaluate the </span>
<span id="t1z_13" class="t v6_13 s1_13">performance of generating image descriptions on a selected subset of languages in the Crossmodal- </span>
<span id="t20_13" class="t v0_13 s1_13">3600 (XM-3600) benchmark in a 4-shot setting, using the Flamingo evaluation protocol (</span><span id="t21_13" class="t v0_13 s2_13">Alayrac </span>
<span id="t22_13" class="t s2_13">et al.</span><span id="t23_13" class="t s1_13">, </span><span id="t24_13" class="t s2_13">2022</span><span id="t25_13" class="t s1_13" data-mappings='[[15,"fi"]]'>), without any ﬁne-tuning for all models. As shown in Table </span><span id="t26_13" class="t s2_13">9</span><span id="t27_13" class="t s1_13">, Gemini models achieve a </span>
<span id="t28_13" class="t s1_13" data-mappings='[[5,"fi"]]'>signiﬁcant improvement over the existing best model, Google PaLI-X. </span>
<span id="t29_13" class="t s0_13">XM-3600 (CIDER) </span><span id="t2a_13" class="t s0_13">Gemini Ultra </span>
<span id="t2b_13" class="t s0_13">4-shot </span>
<span id="t2c_13" class="t s0_13">Gemini Pro </span>
<span id="t2d_13" class="t s0_13">4-shot </span>
<span id="t2e_13" class="t s0_13">Google PaLI-X </span>
<span id="t2f_13" class="t s0_13">4-shot </span>
<span id="t2g_13" class="t s0_13">English </span><span id="t2h_13" class="t s0_13">86.4 </span><span id="t2i_13" class="t s5_13">87.1 </span><span id="t2j_13" class="t s0_13">77.8 </span>
<span id="t2k_13" class="t s0_13">French </span><span id="t2l_13" class="t s5_13">77.9 </span><span id="t2m_13" class="t s0_13">76.7 </span><span id="t2n_13" class="t s0_13">62.5 </span>
<span id="t2o_13" class="t s0_13">Hindi </span><span id="t2p_13" class="t s5_13">31.1 </span><span id="t2q_13" class="t s0_13">29.8 </span><span id="t2r_13" class="t s0_13">22.2 </span>
<span id="t2s_13" class="t s0_13">Modern Hebrew </span><span id="t2t_13" class="t s5_13">54.5 </span><span id="t2u_13" class="t s0_13">52.6 </span><span id="t2v_13" class="t s0_13">38.7 </span>
<span id="t2w_13" class="t s0_13">Romanian </span><span id="t2x_13" class="t s5_13">39.0 </span><span id="t2y_13" class="t s0_13">37.7 </span><span id="t2z_13" class="t s0_13">30.2 </span>
<span id="t30_13" class="t s0_13">Thai </span><span id="t31_13" class="t s5_13">86.7 </span><span id="t32_13" class="t s0_13">77.0 </span><span id="t33_13" class="t s0_13">56.0 </span>
<span id="t34_13" class="t s0_13">Chinese </span><span id="t35_13" class="t s5_13">33.3 </span><span id="t36_13" class="t s0_13">30.2 </span><span id="t37_13" class="t s0_13">27.7 </span>
<span id="t38_13" class="t s0_13">Average (of 7) </span><span id="t39_13" class="t s5_13">58.4 </span><span id="t3a_13" class="t s0_13">55.9 </span><span id="t3b_13" class="t s0_13">45.0 </span>
<span id="t3c_13" class="t v1_13 s1_13">Table 9 </span><span id="t3d_13" class="t s6_13">| </span><span id="t3e_13" class="t v1_13 s7_13">Multilingual image understanding </span><span id="t3f_13" class="t v1_13 s1_13">Gemini models outperform existing models in captioning </span>
<span id="t3g_13" class="t v1_13 s1_13">images in many languages when benchmarked on a subset of languages in XM-3600 dataset (</span><span id="t3h_13" class="t v1_13 s2_13">Thapliyal </span>
<span id="t3i_13" class="t s2_13">et al.</span><span id="t3j_13" class="t s1_13">, </span><span id="t3k_13" class="t s2_13">2022</span><span id="t3l_13" class="t s1_13">). </span>
<span id="t3m_13" class="t s8_13">6 </span>
<span id="t3n_13" class="t v3_13 s9_13">MathVista is a comprehensive mathematical reasoning benchmark consisting of 28 previously published multimodal </span>
<span id="t3o_13" class="t v0_13 s9_13">datasets and three newly created datasets. Our MathVista results were obtained by running the </span><span id="t3p_13" class="t v0_13 sa_13">MathVista authors’ </span>
<span id="t3q_13" class="t sa_13">evaluation script</span><span id="t3r_13" class="t s9_13">. </span>
<span id="t3s_13" class="t s0_13">13 </span></div>
<!-- End text definitions -->


</div>
</body>
</html>
